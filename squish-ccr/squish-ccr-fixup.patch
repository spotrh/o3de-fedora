diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/colourset.cpp.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/colourset.cpp
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/colourset.cpp.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/colourset.cpp	2021-04-28 10:07:49.333506212 -0400
@@ -25,6 +25,7 @@
    -------------------------------------------------------------------------- */
 
 #include <assert.h>
+#include <cstring>
 #include "colourset.h"
 #include "helpers.h"
 
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/config.h.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/config.h
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/config.h.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/config.h	2021-04-28 10:07:49.333506212 -0400
@@ -412,8 +412,9 @@ using namespace ::Concurrency;
 
 #ifdef __GNUC__
 #define assume
-#define doinline
-#define	passreg		__fastcall
+#define doinline	__attribute__((always_inline))
+#define passreg		__attribute__((fastcall))
+//#define	passreg		__fastcall
 #else
 #define assume		__assume
 #define doinline	__forceinline
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/hdrindexfit.h.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/hdrindexfit.h
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/hdrindexfit.h.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/hdrindexfit.h	2021-04-28 10:07:49.333506212 -0400
@@ -48,30 +48,26 @@ private:
   Vec3 m_qerror;
   Scr3 m_berror;
 
-  doinline
   void ErrorEndPoints(int set, Vec3 const &metric, fQuantizer &q, u8 (&closest)[16],
 		      Vec3 const* values, Scr3 const* freq,
 		      int ib, int idxs);
   
-  doinline
   Scr3 ErrorInterpolants(Vec3 const &metric, fQuantizer &q, Vec3 const* values, Scr3 const* freq,
 			 int ib, int idxs, Vec3 &value0, Vec3 &value1, int closest0, int closest1);
-  doinline
+
   Scr3 ErrorInterpolantsS(Vec3 const &metric, fQuantizer &q, Vec3 const* values, Scr3 const* freq,
 			  int ib, int idxs, Vec3 &value0, int closest0);
-  doinline
   Scr3 ErrorInterpolantsE(Vec3 const &metric, fQuantizer &q, Vec3 const* values, Scr3 const* freq,
 			  int ib, int idxs, Vec3 &value1, int closest1);
   
-  doinline
   void BetterInterpolants(int set, Vec3 const &metric, fQuantizer &q, u8 (&closest)[16],
 			  Vec3 const* values, Scr3 const* freq,
 			  int ib, int idxs, Vec3 &value0, Vec3 &value1, int closest0, int closest1);
-  doinline
+
   void BetterInterpolantsS(int set, Vec3 const &metric, fQuantizer &q, u8 (&closest)[16],
 			   Vec3 const* values, Scr3 const* freq,
 			   int ib, int idxs, Vec3 &value0, int closest0);
-  doinline
+
   void BetterInterpolantsE(int set, Vec3 const &metric, fQuantizer &q, u8 (&closest)[16],
 			   Vec3 const* values, Scr3 const* freq,
 			   int ib, int idxs, Vec3 &value1, int closest1);
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/Makefile.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/Makefile
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/Makefile.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/Makefile	2021-04-28 10:09:51.401509651 -0400
@@ -1,26 +1,34 @@
 
 include config
 
-SRC = colourclusterfit.cpp colourblock.cpp colourfit.cpp colourset.cpp colourrangefit.cpp singlecolourfit.cpp alpha.cpp maths.cpp squish.cpp	\
-	paletteclusterfit.cpp paletteblock.cpp palettefit.cpp paletteset.cpp paletterangefit.cpp singlepalettefit.cpp
+CC := gcc
+MAJOR := 1
+MINOR := 0
+VERSION := $(MAJOR).$(MINOR)
+NAME := squish-ccr
+
+SRC = colourclusterfit.cpp colourblock.cpp colourfit.cpp colourset.cpp colourrangefit.cpp coloursinglefit.cpp alpha.cpp maths.cpp squish.cpp	\
+	paletteclusterfit.cpp paletteblock.cpp palettefit.cpp paletteset.cpp paletterangefit.cpp palettesinglefit.cpp alphanormalfit.cpp bitoneblock.cpp hdrfit.cpp bitonefit.cpp hdrset.cpp bitoneset.cpp bitonenormalfit.cpp \
+	palettesinglesnap.cpp bitonerangefit.cpp paletteindexfit.cpp palettenormalfit.cpp bitoneclusterfit.cpp palettechannelfit.cpp hdrblock.cpp colournormalfit.cpp coloursinglesnap.cpp hdrindexfit.cpp hdrrangefit.cpp \
+	hdrsinglefit.cpp hdrsinglesnap.cpp simd.cpp
+
 
 OBJ = $(SRC:%.cpp=%.o)
 
-LIB = libsquish.a
+LIB = libsquish-ccr.so.$(VERSION)
 
 all : $(LIB)
 
 install : $(LIB)
-	install squish.h $(INSTALL_DIR)/include
-	install libsquish.a $(INSTALL_DIR)/lib
+	install squish.h $(INSTALL_DIR)/include/squish-ccr/
+	install libsquish-ccr.so.$(VERSION) $(INSTALL_DIR)/lib
 
 uninstall:
 	$(RM) $(INSTALL_DIR)/include/squish.h
 	$(RM) $(INSTALL_DIR)/lib/libsquish.a
 
 $(LIB) : $(OBJ)
-	$(AR) cr $@ $?
-	ranlib $@
+	$(CC) -shared -Wl,-soname,lib$(NAME).so.$(MAJOR) $^ -o $@
 
 %.o : %.cpp
 	$(CXX) $(CPPFLAGS) -I. $(CXXFLAGS) -o$@ -c $<
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteclusterfit.cpp.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteclusterfit.cpp
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteclusterfit.cpp.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteclusterfit.cpp	2021-04-28 10:07:49.333506212 -0400
@@ -26,6 +26,7 @@
    -------------------------------------------------------------------------- */
 
 #include <assert.h>
+#include <cstdio>
 
 #include "paletteclusterfit.h"
 #include "paletteset.h"
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteindexfit.h.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteindexfit.h
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteindexfit.h.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteindexfit.h	2021-04-28 10:07:49.333506212 -0400
@@ -48,33 +48,30 @@ private:
   Vec4 m_qerror;
   Scr4 m_berror;
 
-  doinline
   void ErrorEndPoints(int set, Vec4 const &metric, vQuantizer &q, int sb, u8 (&closest)[16],
 		      Vec4 const* values, Scr4 const* freq,
 		      int ib, int idxs);
   
-  doinline
   Scr4 ErrorInterpolants(Vec4 const &metric, vQuantizer &q, int sb,
 			 Vec4 const* values, Scr4 const* freq,
 			 int ib, int idxs, Vec4 &value0, Vec4 &value1, int closest0, int closest1);
-  doinline
+
   Scr4 ErrorInterpolantsS(Vec4 const &metric, vQuantizer &q, int sb,
 			  Vec4 const* values, Scr4 const* freq,
 			  int ib, int idxs, Vec4 &value0, int closest0);
-  doinline
+
   Scr4 ErrorInterpolantsE(Vec4 const &metric, vQuantizer &q, int sb,
 			  Vec4 const* values, Scr4 const* freq,
 			  int ib, int idxs, Vec4 &value1, int closest1);
   
-  doinline
   void BetterInterpolants(int set, Vec4 const &metric, vQuantizer &q, int sb, u8 (&closest)[16],
 			  Vec4 const* values, Scr4 const* freq,
 			  int ib, int idxs, Vec4 &value0, Vec4 &value1, int closest0, int closest1);
-  doinline
+
   void BetterInterpolantsS(int set, Vec4 const &metric, vQuantizer &q, int sb, u8 (&closest)[16],
 			   Vec4 const* values, Scr4 const* freq,
 			   int ib, int idxs, Vec4 &value0, int closest0);
-  doinline
+
   void BetterInterpolantsE(int set, Vec4 const &metric, vQuantizer &q, int sb, u8 (&closest)[16],
 			   Vec4 const* values, Scr4 const* freq,
 			   int ib, int idxs, Vec4 &value1, int closest1);
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteset.cpp.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteset.cpp
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteset.cpp.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/paletteset.cpp	2021-04-28 10:07:49.334506228 -0400
@@ -112,7 +112,7 @@ doinline void PaletteSet::GetMasks(int f
     masks[2] = ( 0xFFFFFFFF & 0xFFFF) & ( partmask >> 16);
 }
 
-doinline int PaletteSet::SetMode(int flags) {
+int PaletteSet::SetMode(int flags) {
   /* build a single set only, we permute that later for specific partitions,
    * separate alpha is an exception as that is fixed for each mode
    */
@@ -142,7 +142,7 @@ doinline int PaletteSet::SetMode(int fla
   return flags;
 }
 
-doinline int PaletteSet::SetMode(int flags, int part_or_rot) {
+int PaletteSet::SetMode(int flags, int part_or_rot) {
   /* determine the number of sets and select the partition
   if ((0))
     m_numsets = 1, m_partmask = partitionmasks_1[m_partid = 0]; */
diff -up squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/simd_sse.h.fixup squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/simd_sse.h
--- squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/simd_sse.h.fixup	2017-12-19 23:28:10.000000000 -0500
+++ squish-ccr-deb557d2fa647b191b37a2d8682df54ec8a7cfba/simd_sse.h	2021-04-28 10:07:49.334506228 -0400
@@ -351,64 +351,18 @@ public:
 
 	template<const int n>
 	friend Col3 ShiftLeft( Arg a );
-	template<const int n>
-	friend Col3 ShiftLeft( Arg a )
-	{
-		if ((n) <= 0)
-			return Col3( a.m_v );
-		if ((n) <= 7)
-			return Col3( _mm_slli_epi32( a.m_v, (n) & 7 ) );
-		if ((n) & 7)
-			return Col3( _mm_slli_epi32( _mm_slli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
-
-			return Col3( _mm_slli_si128( a.m_v, (n) >> 3 ) );
-	}
 
 	template<const int n>
 	friend Col3 ShiftRight( Arg a );
-	template<const int n>
-	friend Col3 ShiftRight( Arg a )
-	{
-		if ((n) <= 0)
-			return Col3( a.m_v );
-		if ((n) <= 7)
-			return Col3( _mm_srli_epi32( a.m_v, (n) & 7 ) );
-		if ((n) & 7)
-			return Col3( _mm_srli_epi32( _mm_srli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
-
-			return Col3( _mm_srli_si128( a.m_v, (n) >> 3 ) );
-	}
 
 	template<const int n>
 	friend Col3 ShiftRightHalf( Arg a );
-	template<const int n>
-	friend Col3 ShiftRightHalf( Arg a )
-	{
-		return Col3( (n) > 0 ? _mm_srli_epi64( a.m_v, (n) ) : a.m_v );
-	}
-
-	friend Col3 ShiftRightHalf( Arg a, const int n )
-	{
-		return Col3( _mm_srl_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
-	}
-
-	friend Col3 ShiftRightHalf( Arg a, Arg b )
-	{
-		return Col3( _mm_srl_epi64( a.m_v, b.m_v ) );
-	}
+	friend Col3 ShiftRightHalf( Arg a, const int n );
+	friend Col3 ShiftRightHalf( Arg a, Arg b );
 
 	template<const int n>
 	friend Col3 ShiftLeftHalf( Arg a );
-	template<const int n>
-	friend Col3 ShiftLeftHalf( Arg a )
-	{
-		return Col3( (n) > 0 ? _mm_slli_epi64( a.m_v, (n) ) : a.m_v );
-	}
-
-	friend Col3 ShiftLeftHalf( Arg a, const int n )
-	{
-		return Col3( _mm_sll_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
-	}
+	friend Col3 ShiftLeftHalf( Arg a, const int n );
 
 	template<const int r, const int g, const int b>
 	friend Col3 ShiftLeftLo( Arg v )
@@ -422,140 +376,24 @@ public:
 
 	template<const int n, const int p>
 	friend Col3 MaskBits( Arg a );
-	template<const int n, const int p>
-	friend Col3 MaskBits( Arg a )
-	{
-		if ((p + n) <= 0)
-			return Col3(0);
-		if ((p + n) >= 64)
-			return a;
-
-		// compile time
-		__int64 base = ~(0xFFFFFFFFFFFFFFFFULL << (     (p + n) & 63));
-	//	__int64 base =  (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63));
-		__m128i mask = _mm_setr_epi32(
-		  (int)(base >>  0),
-		  (int)(base >> 32), 0, 0
-		);
-
-		return Col3( _mm_and_si128( a.m_v, mask ) );
-	}
-
-	friend Col3 MaskBits( Arg a, const int n, const int p )
-	{
-		const int val = 64 - (p + n);
-
-		__m128i shift = _mm_max_epi16( _mm_cvtsi32_si128( val ), _mm_set1_epi32( 0 ) );
-		__m128i mask = _mm_setr_epi32(
-		  0xFFFFFFFF,
-		  0xFFFFFFFF, 0, 0
-		);
-
-		mask = _mm_srl_epi64( mask, shift );
-
-		// (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63))
-		return Col3( _mm_and_si128( a.m_v, mask ) );
-	}
+	friend Col3 MaskBits(Arg a, const int n, const int p);
 
 	template<const int n, const int p>
 	friend Col3 CopyBits( Arg left, Arg right );
-	template<const int n, const int p>
-	friend Col3 CopyBits( Arg left, Arg right )
-	{
-		if (!(n))
-			return left;
-		if (!(p))
-			return MaskBits<n, 0>(right);
-		if (((p) + (n)) >= 64)
-			return (left) + ShiftLeftHalf<p>(right);
-
-#if ( SQUISH_USE_XSSE == 4 )
-		return Col3( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
-#else
-		return MaskBits<p, 0>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-	//	return               (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-#endif
-	}
-
-	friend Col3 CopyBits( Arg left, Col3 &right, const int n, const int p )
-	{
-#if ( SQUISH_USE_XSSE == 4 )
-		/* ---- ---bl xxxx xxxx */
-		const int val = (p << 8) + (n << 0);
-
-		right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
-		return Col3( _mm_insert_si64( left.m_v, right.m_v ) );
-#else
-		return MaskBits(left, p, 0) + MaskBits(ShiftLeftHalf(right, p), n, p);
-	//	return         (left      ) + MaskBits(ShiftLeftHalf(right, p), n, p);
-#endif
-	}
+	friend Col3 CopyBits( Arg left, Col3 &right, const int n, const int p );
 
 	template<const int n, const int p>
 	friend Col3 ExtrBits( Arg a );
-	template<const int n, const int p>
-	friend Col3 ExtrBits( Arg a )
-	{
-		if (!(n))
-			return Col3(0);
-		if (!(p))
-			return MaskBits<n, 0>(a);
-		if (((n) + (p)) >= 64)
-			return ShiftRightHalf<p>(a);
-
-#if ( SQUISH_USE_XSSE == 4 )
-		return Col3( _mm_extracti_si64( a.m_v, n, p ) );
-#else
-		return MaskBits<n, 0>(ShiftRightHalf<p>(a));
-#endif
-	}
-
-	friend Col3 ExtrBits( Arg a, const int n, const int p )
-	{
-#if ( SQUISH_USE_XSSE == 4 )
-		/* ---- ----- ---- ---bl */
-		const int val = (p << 8) + (n << 0);
-
-		return Col3( _mm_extract_si64( a.m_v, _mm_cvtsi32_si128( val ) ) );
-#else
-		return MaskBits(ShiftRightHalf(a, p), n, 0);
-#endif
-	}
+	friend Col3 ExtrBits( Arg a, const int n, const int p );
 
 	template<const int n, const int p>
 	friend void ExtrBits( Arg left, Col3 &right );
-	template<const int n, const int p>
-	friend void ExtrBits( Arg left, Col3 &right )
-	{
-		right  = ExtrBits<n, p>( left );
-	}
 
 	template<const int n, const int p>
 	friend void ConcBits( Arg left, Col3 &right );
-	template<const int n, const int p>
-	friend void ConcBits( Arg left, Col3 &right )
-	{
-		right  = ShiftLeft<32>( right );
-		if (n > 0)
-			right += ExtrBits<n, p>( left );
-	}
 
 	template<const int n, const int p>
 	friend void ReplBits( Arg left, Col3 &right );
-	template<const int n, const int p>
-	friend void ReplBits( Arg left, Col3 &right )
-	{
-		if (!n)
-			return;
-		if ((n < 0)) {
-			right  = ExtrBits<-n, p>( left );
-			right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 3 ) );
-		}
-		else {
-			right  = ExtrBits< n, p>( left );
-			right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
-		}
-	}
 
 	friend Col3 Mul16x16u( Arg a, Arg b )
 	{
@@ -651,19 +489,6 @@ public:
 
 	template<const int f, const int t>
 	friend Col3 Exchange( Arg a );
-	template<const int f, const int t>
-	friend Col3 Exchange( Arg a )
-	{
-		if (f == t)
-			return a;
-
-		return Col3( _mm_shuffle_epi32( a.m_v, SQUISH_SSE_SHUF(
-			(t == 0 ? f : (f == 0 ? t : 0)),
-			(t == 1 ? f : (f == 1 ? t : 1)),
-			(t == 2 ? f : (f == 2 ? t : 2)),
-			(t == 3 ? f : (f == 3 ? t : 3))
-		) ) );
-	}
 
 	friend Col3 HorizontalAdd( Arg a )
 	{
@@ -1047,6 +872,199 @@ private:
 	friend class Vec3;
 };
 
+template<const int f, const int t>
+Col3 Exchange( Col3::Arg a )
+{
+	if (f == t)
+		return a;
+
+	return Col3( _mm_shuffle_epi32( a.m_v, SQUISH_SSE_SHUF(
+							       (t == 0 ? f : (f == 0 ? t : 0)),
+							       (t == 1 ? f : (f == 1 ? t : 1)),
+							       (t == 2 ? f : (f == 2 ? t : 2)),
+							       (t == 3 ? f : (f == 3 ? t : 3))
+							       ) ) );
+}
+
+template<const int n>
+Col3 ShiftLeft( Col3::Arg a )
+{
+	if ((n) <= 0)
+		return Col3( a.m_v );
+	if ((n) <= 7)
+		return Col3( _mm_slli_epi32( a.m_v, (n) & 7 ) );
+	if ((n) & 7)
+		return Col3( _mm_slli_epi32( _mm_slli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
+
+	return Col3( _mm_slli_si128( a.m_v, (n) >> 3 ) );
+}
+
+template<const int n>
+Col3 ShiftRight( Col3::Arg a )
+{
+	if ((n) <= 0)
+		return Col3( a.m_v );
+	if ((n) <= 7)
+		return Col3( _mm_srli_epi32( a.m_v, (n) & 7 ) );
+	if ((n) & 7)
+		return Col3( _mm_srli_epi32( _mm_srli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
+
+	return Col3( _mm_srli_si128( a.m_v, (n) >> 3 ) );
+}
+
+template<const int n>
+Col3 ShiftLeftHalf( Col3::Arg a )
+{
+	return Col3( (n) > 0 ? _mm_slli_epi64( a.m_v, (n) ) : a.m_v );
+}
+
+inline Col3 ShiftLeftHalf( Col3::Arg a, const int n )
+{
+	return Col3( _mm_sll_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
+}
+
+template<const int n>
+Col3 ShiftRightHalf( Col3::Arg a )
+{
+	return Col3( (n) > 0 ? _mm_srli_epi64( a.m_v, (n) ) : a.m_v );
+}
+
+inline Col3 ShiftRightHalf( Col3::Arg a, const int n )
+{
+	return Col3( _mm_srl_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
+}
+
+inline Col3 ShiftRightHalf( Col3::Arg a, Col3::Arg b )
+{
+	return Col3( _mm_srl_epi64( a.m_v, b.m_v ) );
+}
+
+template<const int n, const int p>
+Col3 MaskBits( Col3::Arg a )
+{
+	if ((p + n) <= 0)
+		return Col3(0);
+	if ((p + n) >= 64)
+		return a;
+
+	// compile time
+	__int64 base = ~(0xFFFFFFFFFFFFFFFFULL << (     (p + n) & 63));
+	// __int64 base =  (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63));
+	__m128i mask = _mm_setr_epi32(
+				      (int)(base >>  0),
+				      (int)(base >> 32), 0, 0
+				      );
+
+	return Col3( _mm_and_si128( a.m_v, mask ) );
+}
+
+inline Col3 MaskBits( Col3::Arg a, const int n, const int p )
+{
+	const int val = 64 - (p + n);
+
+	__m128i shift = _mm_max_epi16( _mm_cvtsi32_si128( val ), _mm_set1_epi32( 0 ) );
+	__m128i mask = _mm_setr_epi32(
+				      0xFFFFFFFF,
+				      0xFFFFFFFF, 0, 0
+				      );
+
+	mask = _mm_srl_epi64( mask, shift );
+
+	// (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63))
+	return Col3( _mm_and_si128( a.m_v, mask ) );
+}
+
+template<const int n, const int p>
+Col3 CopyBits( Col3::Arg left, Col3::Arg right )
+{
+	if (!(n))
+		return left;
+	if (!(p))
+		return MaskBits<n, 0>(right);
+	if (((p) + (n)) >= 64)
+		return (left) + ShiftLeftHalf<p>(right);
+
+#if ( SQUISH_USE_XSSE == 4 )
+	return Col3( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
+#else
+	return MaskBits<p, 0>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+	//      return               (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+#endif
+}
+
+inline Col3 CopyBits( Col3::Arg left, Col3 &right, const int n, const int p )
+{
+#if ( SQUISH_USE_XSSE == 4 )
+	/* ---- ---bl xxxx xxxx */
+	const int val = (p << 8) + (n << 0);
+
+	right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
+	return Col3( _mm_insert_si64( left.m_v, right.m_v ) );
+#else
+	return MaskBits(left, p, 0) + MaskBits(ShiftLeftHalf(right, p), n, p);
+	//      return         (left      ) + MaskBits(ShiftLeftHalf(right, p), n, p);
+#endif
+}
+
+template<const int n, const int p>
+Col3 ExtrBits( Col3::Arg a )
+{
+	if (!(n))
+		return Col3(0);
+	if (!(p))
+		return MaskBits<n, 0>(a);
+	if (((n) + (p)) >= 64)
+		return ShiftRightHalf<p>(a);
+
+#if ( SQUISH_USE_XSSE == 4 )
+	return Col3( _mm_extracti_si64( a.m_v, n, p ) );
+#else
+	return MaskBits<n, 0>(ShiftRightHalf<p>(a));
+#endif
+}
+
+inline Col3 ExtrBits( Col3::Arg a, const int n, const int p )
+{
+#if ( SQUISH_USE_XSSE == 4 )
+	/* ---- ----- ---- ---bl */
+	const int val = (p << 8) + (n << 0);
+
+	return Col3( _mm_extract_si64( a.m_v, _mm_cvtsi32_si128( val ) ) );
+#else
+	return MaskBits(ShiftRightHalf(a, p), n, 0);
+#endif
+}
+
+template<const int n, const int p>
+void ExtrBits( Col3::Arg left, Col3 &right )
+{
+	right = ExtrBits<n, p>( left );
+}
+
+template<const int n, const int p>
+void ConcBits( Col3::Arg left, Col3 &right )
+{
+	right  = ShiftLeft<32>( right );
+	if (n > 0)
+		right += ExtrBits<n, p>( left );
+}
+
+template<const int n, const int p>
+void ReplBits( Col3::Arg left, Col3 &right )
+{
+	if (!n)
+		return;
+	if ((n < 0)) {
+		right  = ExtrBits<-n, p>( left );
+		right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 3 ) );
+	}
+	else {
+		right  = ExtrBits< n, p>( left );
+		right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
+	}
+}
+
+
 class Col4
 {
 public:
@@ -1305,317 +1323,56 @@ public:
 
 	template<const int n>
 	friend Col4 FillSign( Arg a );
-	template<const int n>
-	friend Col4 FillSign( Arg a )
-	{
-		return Col4( _mm_srai_epi32( _mm_slli_epi32( a.m_v, n ), n ) );
-	}
 
 	template<const int n>
 	friend Col4 ExtendSign( Arg a );
-	template<const int n>
-	friend Col4 ExtendSign( Arg a )
-	{
-		return Col4( _mm_srai_epi32( a.m_v, n ) );
-	}
-	
+
 	template<const int n>
 	friend Col4 ShiftLeft( Arg a );
-	template<const int n>
-	friend Col4 ShiftLeft( Arg a )
-	{
-		if ((n) <= 0)
-			return Col4( a.m_v );
-		if ((n) <= 7)
-			return Col4( _mm_slli_epi32( a.m_v, (n) & 7 ) );
-		if ((n) & 7)
-			return Col4( _mm_slli_epi32( _mm_slli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
-
-			return Col4( _mm_slli_si128( a.m_v, (n) >> 3 ) );
-	}
 
 	template<const int n>
 	friend Col4 ShiftRight( Arg a );
-	template<const int n>
-	friend Col4 ShiftRight( Arg a )
-	{
-		if ((n) <= 0)
-			return Col4( a.m_v );
-		if ((n) <= 7)
-			return Col4( _mm_srli_epi32( a.m_v, (n) & 7 ) );
-		if ((n) & 7)
-			return Col4( _mm_srli_epi32( _mm_srli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
-
-			return Col4( _mm_srli_si128( a.m_v, (n) >> 3 ) );
-	}
 
 	template<const int n>
 	friend Col4 ShiftRightHalf( Arg a );
-	template<const int n>
-	friend Col4 ShiftRightHalf( Arg a )
-	{
-		return Col4( (n) > 0 ? _mm_srli_epi64( a.m_v, (n) ) : a.m_v );
-	}
-
-	friend Col4 ShiftRightHalf( Arg a, const int n )
-	{
-		return Col4( _mm_srl_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
-	}
-
-	friend Col4 ShiftRightHalf( Arg a, Arg b )
-	{
-		return Col4( _mm_srl_epi64( a.m_v, b.m_v ) );
-	}
+	friend Col4 ShiftRightHalf( Arg a, const int n );
+	friend Col4 ShiftRightHalf( Arg a, Arg b );
 
 	template<const int n>
 	friend Col4 ShiftLeftHalf( Arg a );
-	template<const int n>
-	friend Col4 ShiftLeftHalf( Arg a )
-	{
-		return Col4( (n) > 0 ? _mm_slli_epi64( a.m_v, (n) ) : a.m_v );
-	}
-
-	friend Col4 ShiftLeftHalf( Arg a, const int n )
-	{
-		return Col4( _mm_sll_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
-	}
+	friend Col4 ShiftLeftHalf( Arg a, const int n );
 
 	template<const int r, const int g, const int b, const int a>
 	friend Col4 ShiftLeftLo( Arg v );
-	template<const int r, const int g, const int b, const int a>
-	friend Col4 ShiftLeftLo( Arg v )
-	{
-		// (1 << r, 1 << g, 1 << b, 1 << a);
-		Col4 p2; p2.SetRGBApow2<0>(r, g, b, a);
-
-#if ( SQUISH_USE_SSE >= 4 )
-		return Col4( _mm_mullo_epi32( v.m_v, p2.m_v ) );
-#else
-		return Col4( _mm_mullo_epi16( v.m_v, p2.m_v ) );
-#endif
-	}
 
 	template<const int n, const int p>
 	friend Col4 MaskBits( Arg a );
-	template<const int n, const int p>
-	friend Col4 MaskBits( Arg a )
-	{
-		if (((p) + (n)) <= 0)
-			return Col4(0);
-		if (((p) + (n)) >= 64)
-			return a;
-
-		// compile time
-		__int64 base = ~(0xFFFFFFFFFFFFFFFFULL << (     ((p) + (n)) & 63));
-	//	__int64 base =  (0xFFFFFFFFFFFFFFFFULL >> (64 - ((p) + (n)) & 63));
-		__m128i mask = _mm_setr_epi32(
-		  (int)(base >>  0),
-		  (int)(base >> 32), 0, 0
-		);
-
-		return Col4( _mm_and_si128( a.m_v, mask ) );
-	}
-
-	friend Col4 MaskBits( Arg a, const int n, const int p )
-	{
-		const int val = 64 - ((p) + (n));
-
-		__m128i shift = _mm_max_epi16( _mm_cvtsi32_si128( val ), _mm_set1_epi32( 0 ) );
-		__m128i mask = _mm_setr_epi32(
-		  0xFFFFFFFF,
-		  0xFFFFFFFF, 0, 0
-		);
-
-		mask = _mm_srl_epi64( mask, shift );
-
-		// (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63))
-		return Col4( _mm_and_si128( a.m_v, mask ) );
-	}
+	friend Col4 MaskBits( Arg a, const int n, const int p );
 
 	template<const int n, const int p>
 	friend Col4 CopyBits( Arg left, Arg right );
-	template<const int n, const int p>
-	friend Col4 CopyBits( Arg left, Arg right )
-	{
-		if (!(n))
-			return left;
-		if (!(p))
-			return MaskBits<n, 0>(right);
-		if (((p) + (n)) >= 64)
-			return (left) + ShiftLeftHalf<p>(right);
-
-#if ( SQUISH_USE_XSSE == 4 )
-		return Col4( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
-#else
-		return MaskBits<p, 0>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-	//	return               (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-#endif
-	}
-
-	friend Col4 CopyBits( Arg left, Col4& right, const int n, const int p )
-	{
-#if ( SQUISH_USE_XSSE == 4 )
-		/* ---- ---bl xxxx xxxx */
-		const int val = (p << 8) + (n << 0);
-
-		right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
-		return Col4( _mm_insert_si64( left.m_v, right.m_v ) );
-#else
-		return MaskBits(left, p, 0) + MaskBits(ShiftLeftHalf(right, p), n, p);
-	//	return         (left      ) + MaskBits(ShiftLeftHalf(right, p), n, p);
-#endif
-	}
+	friend Col4 CopyBits( Arg left, Col4& right, const int n, const int p );
 
 	template<const int n, const int p>
 	friend Col4 KillBits( Arg a );
-	template<const int n, const int p>
-	friend Col4 KillBits( Arg a )
-	{
-		if (!n || (p >= 64))
-			return a;
-		if (!p && (n >= 64))
-			return Col4(0);
-
-		// compile time
-		__int64 base1 =  (0xFFFFFFFFFFFFFFFFULL << (     (p + 0) & 63));
-		__int64 base2 =  (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63));
-	//	__int64 base1 = ~(0xFFFFFFFFFFFFFFFFULL >> (64 - (p + 0) & 63));
-	//	__int64 base2 = ~(0xFFFFFFFFFFFFFFFFULL << (64 - (p + n) & 63));
-
-		__m128i mask;
-
-		if ((p + n) >= 64)
-		  base2 = 0xFFFFFFFFFFFFFFFFULL;
-
-		mask = _mm_setr_epi32(
-		  (int)((base1 ^ base2) >>  0),
-		  (int)((base1 ^ base2) >> 32), 0, 0
-		);
-
-		return Col4( _mm_and_si128( a.m_v, mask ) );
-	}
-
-	friend Col4 KillBits( Arg a, const int n, const int p )
-	{
-		const int val1 =      (p + 0);
-		const int val2 = 64 - (p + n);
-
-		__m128i shift1 = _mm_max_epi16( _mm_cvtsi32_si128( val1 ), _mm_set1_epi32( 0 ) );
-		__m128i shift2 = _mm_max_epi16( _mm_cvtsi32_si128( val2 ), _mm_set1_epi32( 0 ) );
-		__m128i mask1 = _mm_setr_epi32(
-		  0xFFFFFFFF,
-		  0xFFFFFFFF, 0, 0
-		);
-		__m128i mask2 = _mm_setr_epi32(
-		  0xFFFFFFFF,
-		  0xFFFFFFFF, 0, 0
-		);
-
-		mask1 = _mm_sll_epi64( mask1, shift1 );
-		mask2 = _mm_srl_epi64( mask2, shift2 );
-
-		return Col4( _mm_and_si128( a.m_v, _mm_xor_si128( mask1, mask2 ) ) );
-	}
+	friend Col4 KillBits( Arg a, const int n, const int p );
 
 	template<const int n, const int p>
 	friend Col4 InjtBits( Arg left, Arg right );
-	template<const int n, const int p>
-	friend Col4 InjtBits( Arg left, Arg right )
-	{
-		if (!n || (p >= 64))
-			return right;
-		if ((p + n) >= 64)
-			return KillBits<n, p>(left) + ShiftLeftHalf<p>(right);
-	//		return               (left) + ShiftLeftHalf<p>(right);
-
-
-#if ( SQUISH_USE_XSSE == 4 )
-		return Col4( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
-#else
-		return KillBits<n, p>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-	//	return               (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
-#endif
-	}
-
-	friend Col4 InjtBits( Arg left, Col4& right, const int n, const int p )
-	{
-#if ( SQUISH_USE_XSSE == 4 )
-		/* ---- ---bl xxxx xxxx */
-		const int val = (p << 8) + (n << 0);
-
-		right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
-		return Col4( _mm_insert_si64( left.m_v, right.m_v ) );
-#else
-		return KillBits(left, n, p) + MaskBits(ShiftLeftHalf(right, p), n, p);
-	//	return         (left      ) + MaskBits(ShiftLeftHalf(right, p), n, p);
-#endif
-	}
+	friend Col4 InjtBits( Arg left, Col4& right, const int n, const int p );
 
 	template<const int n, const int p>
 	friend Col4 ExtrBits( Arg a );
-	template<const int n, const int p>
-	friend Col4 ExtrBits( Arg a )
-	{
-		if (!n)
-			return Col4(0);
-		if (!p)
-			return MaskBits<n, 0>(a);
-		if ((n + p) >= 64)
-			return ShiftRightHalf<p>(a);
-
-#if ( SQUISH_USE_XSSE == 4 )
-		return Col4( _mm_extracti_si64( a.m_v, n, p ) );
-#else
-		return MaskBits<n, 0>(ShiftRightHalf<p>(a));
-#endif
-	}
-
-	friend Col4 ExtrBits( Arg a, const int n, const int p )
-	{
-#if ( SQUISH_USE_XSSE == 4 )
-		/* ---- ----- ---- ---bl */
-		const int val = (p << 8) + (n << 0);
-
-		return Col4( _mm_extract_si64( a.m_v, _mm_cvtsi32_si128( val ) ) );
-#else
-		return MaskBits(ShiftRightHalf(a, p), n, 0);
-#endif
-	}
+	friend Col4 ExtrBits( Arg a, const int n, const int p );
 
 	template<const int n, const int p>
 	friend void ExtrBits( Arg left, Col4 &right );
-	template<const int n, const int p>
-	friend void ExtrBits( Arg left, Col4 &right )
-	{
-		right  = ExtrBits<n, p>( left );
-	}
 
 	template<const int n, const int p>
 	friend void ConcBits( Arg left, Col4 &right );
-	template<const int n, const int p>
-	friend void ConcBits( Arg left, Col4 &right )
-	{
-		right  = ShiftLeft<32>( right );
-		if (n > 0)
-			right += ExtrBits<n, p>( left );
-	}
 
 	template<const int n, const int p>
 	friend void ReplBits( Arg left, Col4 &right );
-	template<const int n, const int p>
-	friend void ReplBits( Arg left, Col4 &right )
-	{
-		if (!n)
-			return;
-		if ((n < 0)) {
-			right  = ExtrBits<-n, p>( left );
-			right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 3 ) );
-		}
-		else {
-			right  = ExtrBits< n, p>( left );
-			right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
-		}
-	}
 
 	friend Col4 RevsBits( Col4::Arg v )
 	{
@@ -1679,19 +1436,6 @@ public:
 
 	template<const int f, const int t>
 	friend Col4 Shuffle( Arg a );
-	template<const int f, const int t>
-	friend Col4 Shuffle( Arg a )
-	{
-		if (f == t)
-			return a;
-
-		return Col4( _mm_shuffle_epi32( a.m_v, SQUISH_SSE_SHUF(
-			(t == 0 ? f : 0),
-			(t == 1 ? f : 1),
-			(t == 2 ? f : 2),
-			(t == 3 ? f : 3)
-		) ) );
-	}
 
 	template<const int f, const int t>
 	friend Col4 Exchange( Arg a );
@@ -1996,11 +1740,6 @@ public:
 
 	template<const int value>
 	friend Col4 IsValue( Arg v );
-	template<const int value>
-	friend Col4 IsValue( Arg v )
-	{
-		return Col4( _mm_cmpeq_epi32( v.m_v, _mm_set1_epi32( value ) ) );
-	}
 
 	friend Col4 TransferA( Arg left, Arg right )
 	{
@@ -2100,18 +1839,9 @@ public:
 
 		a = Col4( r );
 	}
-	
-	friend void UnpackBytes( Col4 &a, const int &loc )
-	{
-		__m128i
 
-		r = _mm_cvtsi32_si128 ( loc );
-		r = _mm_unpacklo_epi8( r, r );
-		r = _mm_unpacklo_epi16( r, r );
-		
-		a = ExtendSign<24>( Col4( r ) );
-	}
-	
+	friend void UnpackBytes( Col4 &a, const int &loc );
+
 	friend void UnpackWords( Col4 &a, const unsigned__int64 &loc )
 	{
 		__m128i
@@ -2121,17 +1851,9 @@ public:
 
 		a = Col4( r );
 	}
-	
-	friend void UnpackWords( Col4 &a, const __int64 &loc )
-	{
-		__m128i
 
-		r = _mm_loadl_epi64( (__m128i *)&loc );
-		r = _mm_unpacklo_epi16( r, r );
-		
-		a = ExtendSign<16>( Col4( r ) );
-	}
-	
+	friend void UnpackWords( Col4 &a, const __int64 &loc );
+
 	// clamp the output to [0, 1]
 	Col4 Clamp() const {
 		Col4 const one (0xFF);
@@ -2202,14 +1924,10 @@ public:
 	friend void StoreUnaligned( Arg a, s16* loc ) {
 	  PackWords( a, (__int64&) (*((__int64 *)loc)) ); }
 	
-	friend void LoadUnaligned( Col4 &a, const u8* loc ) {
-	  UnpackBytes( a, (const unsigned int&) (*((const unsigned int *)loc)) ); }
-	friend void LoadUnaligned( Col4 &a, const u16* loc ) {
-	  UnpackWords( a, (const unsigned__int64&) (*((const unsigned__int64 *)loc)) ); }
-	friend void LoadUnaligned( Col4 &a, const s8* loc ) {
-	  UnpackBytes( a, (const int&) (*((const int *)loc)) ); }
-	friend void LoadUnaligned( Col4 &a, const s16* loc ) {
-	  UnpackWords( a, (const __int64&) (*((const __int64 *)loc)) ); }
+	friend void LoadUnaligned( Col4 &a, const u8* loc );
+	friend void LoadUnaligned( Col4 &a, const u16* loc );
+	friend void LoadUnaligned( Col4 &a, const s8* loc );
+	friend void LoadUnaligned( Col4 &a, const s16* loc );
 
 	void SwapRGBA( Col4 &with )
 	{
@@ -2226,6 +1944,346 @@ private:
 	friend class Col8;
 };
 
+template<const int value>
+Col4 IsValue( Col4::Arg v )
+{
+        return Col4( _mm_cmpeq_epi32( v.m_v, _mm_set1_epi32( value ) ) );
+}
+
+template<const int n>
+Col4 ExtendSign( Col4::Arg a )
+{
+	return Col4( _mm_srai_epi32( a.m_v, n ) );
+}
+
+inline void UnpackBytes( Col4 &a, const int &loc )
+{
+	__m128i
+
+	r = _mm_cvtsi32_si128 ( loc );
+	r = _mm_unpacklo_epi8( r, r );
+	r = _mm_unpacklo_epi16( r, r );
+
+	a = ExtendSign<24>( Col4( r ) );
+}
+
+inline void UnpackWords( Col4 &a, const __int64 &loc )
+{
+	__m128i
+
+	r = _mm_loadl_epi64( (__m128i *)&loc );
+	r = _mm_unpacklo_epi16( r, r );
+
+	a = ExtendSign<16>( Col4( r ) );
+}
+
+inline void LoadUnaligned( Col4 &a, const u8* loc ) {
+	UnpackBytes( a, (const unsigned int&) (*((const unsigned int *)loc)) );
+}
+
+inline void LoadUnaligned( Col4 &a, const u16* loc ) {
+	UnpackWords( a, (const unsigned__int64&) (*((const unsigned__int64 *)loc)) );
+}
+
+inline void LoadUnaligned( Col4 &a, const s8* loc ) {
+	UnpackBytes( a, (const int&) (*((const int *)loc)) );
+}
+
+inline void LoadUnaligned( Col4 &a, const s16* loc ) {
+	UnpackWords( a, (const __int64&) (*((const __int64 *)loc)) );
+}
+
+template<const int f, const int t>
+Col4 Shuffle( Col4::Arg a )
+{
+	if (f == t)
+		return a;
+
+	return Col4( _mm_shuffle_epi32( a.m_v, SQUISH_SSE_SHUF(
+							       (t == 0 ? f : 0),
+							       (t == 1 ? f : 1),
+							       (t == 2 ? f : 2),
+							       (t == 3 ? f : 3)
+							       ) ) );
+}
+
+template<const int n>
+Col4 FillSign( Col4::Arg a )
+{
+	return Col4( _mm_srai_epi32( _mm_slli_epi32( a.m_v, n ), n ) );
+}
+
+template<const int n>
+Col4 ShiftLeft( Col4::Arg a )
+{
+	if ((n) <= 0)
+		return Col4( a.m_v );
+	if ((n) <= 7)
+		return Col4( _mm_slli_epi32( a.m_v, (n) & 7 ) );
+	if ((n) & 7)
+		return Col4( _mm_slli_epi32( _mm_slli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
+
+	return Col4( _mm_slli_si128( a.m_v, (n) >> 3 ) );
+}
+
+template<const int n>
+Col4 ShiftRight( Col4::Arg a )
+{
+	if ((n) <= 0)
+		return Col4( a.m_v );
+	if ((n) <= 7)
+		return Col4( _mm_srli_epi32( a.m_v, (n) & 7 ) );
+	if ((n) & 7)
+		return Col4( _mm_srli_epi32( _mm_srli_si128( a.m_v, (n) >> 3 ), (n) & 7 ) );
+
+	return Col4( _mm_srli_si128( a.m_v, (n) >> 3 ) );
+}
+
+template<const int n>
+Col4 ShiftRightHalf( Col4::Arg a )
+{
+	return Col4( (n) > 0 ? _mm_srli_epi64( a.m_v, (n) ) : a.m_v );
+}
+
+inline Col4 ShiftRightHalf( Col4::Arg a, const int n )
+{
+	return Col4( _mm_srl_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
+}
+
+inline Col4 ShiftRightHalf( Col4::Arg a, Col4::Arg b )
+{
+	return Col4( _mm_srl_epi64( a.m_v, b.m_v ) );
+}
+
+template<const int n>
+Col4 ShiftLeftHalf( Col4::Arg a )
+{
+	return Col4( (n) > 0 ? _mm_slli_epi64( a.m_v, (n) ) : a.m_v );
+}
+
+inline Col4 ShiftLeftHalf( Col4::Arg a, const int n )
+{
+	return Col4( _mm_sll_epi64( a.m_v, _mm_cvtsi32_si128( n ) ) );
+}
+
+template<const int r, const int g, const int b, const int a>
+Col4 ShiftLeftLo( Col4::Arg v )
+{
+	// (1 << r, 1 << g, 1 << b, 1 << a);
+	Col4 p2; p2.SetRGBApow2<0>(r, g, b, a);
+
+#if ( SQUISH_USE_SSE >= 4 )
+	return Col4( _mm_mullo_epi32( v.m_v, p2.m_v ) );
+#else
+	return Col4( _mm_mullo_epi16( v.m_v, p2.m_v ) );
+#endif
+}
+
+template<const int n, const int p>
+Col4 MaskBits( Col4::Arg a )
+{
+	if (((p) + (n)) <= 0)
+		return Col4(0);
+	if (((p) + (n)) >= 64)
+		return a;
+
+	// compile time
+	__int64 base = ~(0xFFFFFFFFFFFFFFFFULL << (     ((p) + (n)) & 63));
+        // __int64 base =  (0xFFFFFFFFFFFFFFFFULL >> (64 - ((p) + (n)) & 63));
+	__m128i mask = _mm_setr_epi32(
+				      (int)(base >>  0),
+				      (int)(base >> 32), 0, 0
+				      );
+
+	return Col4( _mm_and_si128( a.m_v, mask ) );
+}
+
+inline Col4 MaskBits( Col4::Arg a, const int n, const int p )
+{
+	const int val = 64 - ((p) + (n));
+
+	__m128i shift = _mm_max_epi16( _mm_cvtsi32_si128( val ), _mm_set1_epi32( 0 ) );
+	__m128i mask = _mm_setr_epi32(
+				      0xFFFFFFFF,
+				      0xFFFFFFFF, 0, 0
+				      );
+
+	mask = _mm_srl_epi64( mask, shift );
+
+	// (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63))
+	return Col4( _mm_and_si128( a.m_v, mask ) );
+}
+
+template<const int n, const int p>
+Col4 CopyBits( Col4::Arg left, Col4::Arg right )
+{
+	if (!(n))
+		return left;
+	if (!(p))
+		return MaskBits<n, 0>(right);
+	if (((p) + (n)) >= 64)
+		return (left) + ShiftLeftHalf<p>(right);
+
+#if ( SQUISH_USE_XSSE == 4 )
+	return Col4( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
+#else
+	return MaskBits<p, 0>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+	// return (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+#endif
+}
+
+inline Col4 CopyBits( Col4::Arg left, Col4& right, const int n, const int p )
+{
+#if ( SQUISH_USE_XSSE == 4 )
+	/* ---- ---bl xxxx xxxx */
+	const int val = (p << 8) + (n << 0);
+
+	right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
+	return Col4( _mm_insert_si64( left.m_v, right.m_v ) );
+#else
+	return MaskBits(left, p, 0) + MaskBits(ShiftLeftHalf(right, p), n, p);
+	// return (left) + MaskBits(ShiftLeftHalf(right, p), n, p);
+#endif
+}
+
+template<const int n, const int p>
+Col4 KillBits( Col4::Arg a )
+{
+	if (!n || (p >= 64))
+		return a;
+	if (!p && (n >= 64))
+		return Col4(0);
+
+	// compile time
+	__int64 base1 =  (0xFFFFFFFFFFFFFFFFULL << (     (p + 0) & 63));
+	__int64 base2 =  (0xFFFFFFFFFFFFFFFFULL >> (64 - (p + n) & 63));
+        // __int64 base1 = ~(0xFFFFFFFFFFFFFFFFULL >> (64 - (p + 0) & 63));
+        // __int64 base2 = ~(0xFFFFFFFFFFFFFFFFULL << (64 - (p + n) & 63));
+
+	__m128i mask;
+
+	if ((p + n) >= 64)
+		base2 = 0xFFFFFFFFFFFFFFFFULL;
+
+	mask = _mm_setr_epi32(
+			      (int)((base1 ^ base2) >>  0),
+			      (int)((base1 ^ base2) >> 32), 0, 0
+			      );
+
+	return Col4( _mm_and_si128( a.m_v, mask ) );
+}
+
+inline Col4 KillBits( Col4::Arg a, const int n, const int p )
+{
+	const int val1 =      (p + 0);
+	const int val2 = 64 - (p + n);
+
+	__m128i shift1 = _mm_max_epi16( _mm_cvtsi32_si128( val1 ), _mm_set1_epi32( 0 ) );
+	__m128i shift2 = _mm_max_epi16( _mm_cvtsi32_si128( val2 ), _mm_set1_epi32( 0 ) );
+	__m128i mask1 = _mm_setr_epi32(
+				       0xFFFFFFFF,
+				       0xFFFFFFFF, 0, 0
+				       );
+	__m128i mask2 = _mm_setr_epi32(
+				       0xFFFFFFFF,
+				       0xFFFFFFFF, 0, 0
+				       );
+
+	mask1 = _mm_sll_epi64( mask1, shift1 );
+	mask2 = _mm_srl_epi64( mask2, shift2 );
+
+	return Col4( _mm_and_si128( a.m_v, _mm_xor_si128( mask1, mask2 ) ) );
+}
+
+template<const int n, const int p>
+Col4 InjtBits( Col4::Arg left, Col4::Arg right )
+{
+	if (!n || (p >= 64))
+		return right;
+	if ((p + n) >= 64)
+		return KillBits<n, p>(left) + ShiftLeftHalf<p>(right);
+        // return (left) + ShiftLeftHalf<p>(right);
+
+#if ( SQUISH_USE_XSSE == 4 )
+	return Col4( _mm_inserti_si64( left.m_v, right.m_v, n, p ) );
+#else
+	return KillBits<n, p>(left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+	// return (left) + MaskBits<n, p>(ShiftLeftHalf<p>(right));
+#endif
+}
+
+inline Col4 InjtBits( Col4::Arg left, Col4& right, const int n, const int p )
+{
+#if ( SQUISH_USE_XSSE == 4 )
+	/* ---- ---bl xxxx xxxx */
+	const int val = (p << 8) + (n << 0);
+
+	right.m_v = _mm_unpacklo_epi64( right.m_v, _mm_cvtsi32_si128( val ) );
+	return Col4( _mm_insert_si64( left.m_v, right.m_v ) );
+#else
+	return KillBits(left, n, p) + MaskBits(ShiftLeftHalf(right, p), n, p);
+	// return (left) + MaskBits(ShiftLeftHalf(right, p), n, p);
+#endif
+}
+
+template<const int n, const int p>
+Col4 ExtrBits( Col4::Arg a )
+{
+	if (!n)
+		return Col4(0);
+	if (!p)
+		return MaskBits<n, 0>(a);
+	if ((n + p) >= 64)
+		return ShiftRightHalf<p>(a);
+
+#if ( SQUISH_USE_XSSE == 4 )
+	return Col4( _mm_extracti_si64( a.m_v, n, p ) );
+#else
+	return MaskBits<n, 0>(ShiftRightHalf<p>(a));
+#endif
+}
+
+inline Col4 ExtrBits( Col4::Arg a, const int n, const int p )
+{
+#if ( SQUISH_USE_XSSE == 4 )
+	/* ---- ----- ---- ---bl */
+	const int val = (p << 8) + (n << 0);
+
+	return Col4( _mm_extract_si64( a.m_v, _mm_cvtsi32_si128( val ) ) );
+#else
+	return MaskBits(ShiftRightHalf(a, p), n, 0);
+#endif
+}
+
+template<const int n, const int p>
+void ExtrBits( Col4::Arg left, Col4 &right )
+{
+	right  = ExtrBits<n, p>( left );
+}
+
+template<const int n, const int p>
+void ConcBits( Col4::Arg left, Col4 &right )
+{
+	right  = ShiftLeft<32>( right );
+	if (n > 0)
+		right += ExtrBits<n, p>( left );
+}
+
+template<const int n, const int p>
+void ReplBits( Col4::Arg left, Col4 &right )
+{
+	if (!n)
+		return;
+	if ((n < 0)) {
+		right  = ExtrBits<-n, p>( left );
+		right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 3 ) );
+	}
+	else {
+		right  = ExtrBits< n, p>( left );
+		right.m_v = _mm_shuffle_epi32( right.m_v, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
+	}
+}
+
 #if	!defined(SQUISH_USE_PRE)
 inline Col3 LengthSquared( Col3::Arg v )
 {
@@ -2420,12 +2478,7 @@ public:
 
 	template<const int n>
 	friend Col8 ShiftUp(Arg a);
-	template<const int n>
-	friend Col8 ShiftUp(Arg a)
-	{
-		return Col8( _mm_slli_si128( a.m_v, n << 1 ) );
-	}
-	
+
 #pragma warning ( push )
 #pragma warning ( disable : 4100 )
 	friend Col4 ExpandUpper(Arg a, const unsigned dummy) {
@@ -2623,6 +2676,12 @@ private:
 	friend class Vec4;
 };
 
+template<const int n>
+Col8 ShiftUp( Col8::Arg a)
+{
+        return Col8( _mm_slli_si128( a.m_v, n << 1 ) );
+}
+
 #define VEC4_CONST( X ) Vec4( X )
 
 class Vec3
@@ -2863,16 +2922,6 @@ public:
 
 	template<const int n>
 	friend Vec3 RotateLeft( Arg a );
-	template<const int n>
-	friend Vec3 RotateLeft( Arg a )
-	{
-		return Vec3( _mm_shuffle_ps( a.m_v , a.m_v , SQUISH_SSE_SHUF(
-			(n + 0) % 3,
-			(n + 1) % 3,
-			(n + 2) % 3,
-			3
-		) ) );
-	}
 
 	friend Vec3 HorizontalAdd( Arg a )
 	{
@@ -3063,37 +3112,6 @@ public:
 
 	template<const bool disarm>
 	friend Vec3 Complement( Arg left );
-	template<const bool disarm>
-	friend Vec3 Complement( Arg left )
-	{
-		__m128 ren, res, rez;
-
-		ren = left.m_v;
-		rez = _mm_set1_ps( 1.0f );
-		res = _mm_mul_ps( left.m_v, left.m_v );
-#if ( SQUISH_USE_SSE >= 3 )
-		res = _mm_hadd_ps( res, res );
-#else
-		res = _mm_add_ps( res, _mm_shuffle_ps( res, res, SQUISH_SSE_SHUF( 1, 0, 1, 0 ) ) );
-#endif
-		if (!disarm) {
-			// correct x² + y² > 1.0f by renormalization
-			if ( _mm_comigt_ss( res, rez ) ) {
-				res = ReciprocalSqrt( Vec3(res) ).m_v;
-				res = _mm_shuffle_ps( res, res, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
-
-				ren = _mm_mul_ps( ren, res );
-				res = rez;
-			}
-		}
-		
-		rez = _mm_sub_ps( rez, _mm_min_ps( rez, res ) );
-		rez = _mm_sqrt_ps( rez );
-		res = _mm_movelh_ps( left.m_v, rez );
-
-		// sqrt(1.0f - (x*x + y*y))
-		return Vec3( res );
-	}
 
 	template<const bool disarm>
 	friend Vec3 Complement( Vec3 &left, Vec3 &right );
@@ -3194,19 +3212,6 @@ public:
 
 	template<const bool round>
 	friend Col3 FloatToInt( Arg v );
-	template<const bool round>
-	friend Col3 FloatToInt( Arg v )
-	{
-#if ( SQUISH_USE_SSE == 1 )
-		...
-#else
-		// use SSE2 instructions
-		if (round)
-		      return Col3( _mm_cvtps_epi32( v.m_v ) );
-		else
-		      return Col3( _mm_cvttps_epi32( v.m_v ) );
-#endif
-	}
 
 	friend Vec3 Truncate( Arg v )
 	{
@@ -3355,6 +3360,63 @@ private:
 };
 
 template<const bool round>
+Col3 FloatToInt( Vec3::Arg v )
+{
+#if ( SQUISH_USE_SSE == 1 )
+	...
+#else
+	// use SSE2 instructions
+	if (round)
+		return Col3( _mm_cvtps_epi32( v.m_v ) );
+	else
+		return Col3( _mm_cvttps_epi32( v.m_v ) );
+#endif
+}
+
+template<const int n>
+Vec3 RotateLeft( Vec3::Arg a )
+{
+	return Vec3( _mm_shuffle_ps( a.m_v , a.m_v , SQUISH_SSE_SHUF(
+								     (n + 0) % 3,
+								     (n + 1) % 3,
+								     (n + 2) % 3,
+								     3
+								     ) ) );
+}
+
+template<const bool disarm>
+Vec3 Complement( Vec3::Arg left )
+{
+	__m128 ren, res, rez;
+
+	ren = left.m_v;
+	rez = _mm_set1_ps( 1.0f );
+	res = _mm_mul_ps( left.m_v, left.m_v );
+#if ( SQUISH_USE_SSE >= 3 )
+	res = _mm_hadd_ps( res, res );
+#else
+	res = _mm_add_ps( res, _mm_shuffle_ps( res, res, SQUISH_SSE_SHUF( 1, 0, 1, 0 ) ) );
+#endif
+	if (!disarm) {
+		// correct xï¿½ + yï¿½ > 1.0f by renormalization
+		if ( _mm_comigt_ss( res, rez ) ) {
+			res = ReciprocalSqrt( Vec3(res) ).m_v;
+			res = _mm_shuffle_ps( res, res, SQUISH_SSE_SHUF( 0, 0, 0, 0 ) );
+
+			ren = _mm_mul_ps( ren, res );
+			res = rez;
+ 		}
+	}
+
+	rez = _mm_sub_ps( rez, _mm_min_ps( rez, res ) );
+	rez = _mm_sqrt_ps( rez );
+	res = _mm_movelh_ps( left.m_v, rez );
+
+	// sqrt(1.0f - (x*x + y*y))
+	return Vec3( res );
+}
+
+template<const bool round>
 Col3 FloatToUHalf( Vec3::Arg v );
 template<const bool round>
 Col3 FloatToUHalf( Vec3::Arg v )
@@ -3382,7 +3444,7 @@ Col3 FloatToSHalf( Vec3::Arg v )
 	return h;
 }
 
-Vec3 UHalfToFloat( Col3::Arg v )
+inline Vec3 UHalfToFloat( Col3::Arg v )
 {
 	Vec3 f;
 
@@ -3393,7 +3455,7 @@ Vec3 UHalfToFloat( Col3::Arg v )
 	return f;
 }
 
-Vec3 SHalfToFloat( Col3::Arg v )
+inline Vec3 SHalfToFloat( Col3::Arg v )
 {
 	Vec3 f;
 
@@ -3505,16 +3567,8 @@ public:
 	}
 
 	template<class dtyp> friend Vec4 LoVec4(Col8 const&v, const dtyp& dummy);
-	template<class dtyp> friend Vec4 LoVec4(Col8 const&v, const dtyp& dummy)
-	{
-		return Vec4( LoCol4( v, dummy ) );
-	}
 
 	template<class dtyp> friend Vec4 HiVec4(Col8 const&v, const dtyp& dummy);
-	template<class dtyp> friend Vec4 HiVec4(Col8 const&v, const dtyp& dummy)
-	{
-		return Vec4( HiCol4( v, dummy ) );
-	}
 
 	void StoreX(float *x) const { _mm_store_ss(x, m_v); }
 	void StoreY(float *y) const { _mm_store_ss(y, _mm_shuffle_ps( m_v, m_v, SQUISH_SSE_SPLAT( 1 ) )); }
@@ -3732,16 +3786,6 @@ public:
 
 	template<const int a, const int b, const int c, const int d>
 	friend Vec4 Merge( Arg lo, Arg hi );
-	template<const int a, const int b, const int c, const int d>
-	friend Vec4 Merge( Arg lo, Arg hi )
-	{
-		return Vec4( _mm_shuffle_ps( lo.m_v , hi.m_v , SQUISH_SSE_SHUF(
-			a % 4,
-			b % 4,
-			c % 4,
-			d % 4
-		) ) );
-	}
 
 	template<const int f, const int t>
 	friend Vec4 Shuffle( Arg a );
@@ -4131,19 +4175,6 @@ public:
 
 	template<const bool round>
 	friend Col4 FloatToInt( Vec4::Arg v );
-	template<const bool round>
-	friend Col4 FloatToInt( Vec4::Arg v )
-	{
-#if ( SQUISH_USE_SSE == 1 )
-		...
-#else
-		// use SSE2 instructions
-		if (round)
-		      return Col4( _mm_cvtps_epi32( v.m_v ) );
-		else
-		      return Col4( _mm_cvttps_epi32( v.m_v ) );
-#endif
-	}
 
 	friend Vec4 Truncate( Arg v )
 	{
@@ -4421,6 +4452,41 @@ private:
 };
 
 template<const bool round>
+Col4 FloatToInt( Vec4::Arg v )
+{
+#if ( SQUISH_USE_SSE == 1 )
+	...
+#else
+	// use SSE2 instructions
+	if (round)
+		return Col4( _mm_cvtps_epi32( v.m_v ) );
+	else
+		return Col4( _mm_cvttps_epi32( v.m_v ) );
+#endif
+}
+
+template<class dtyp> Vec4 LoVec4(Col8 const&v, const dtyp& dummy)
+{
+	return Vec4( LoCol4( v, dummy ) );
+}
+
+template<class dtyp> Vec4 HiVec4(Col8 const&v, const dtyp& dummy)
+{
+	return Vec4( HiCol4( v, dummy ) );
+}
+
+template<const int a, const int b, const int c, const int d>
+Vec4 Merge( Vec4::Arg lo, Vec4::Arg hi )
+{
+	return Vec4( _mm_shuffle_ps( lo.m_v , hi.m_v , SQUISH_SSE_SHUF(
+								       a % 4,
+								       b % 4,
+								       c % 4,
+								       d % 4
+								       ) ) );
+}
+
+template<const bool round>
 Col4 FloatToUHalf( Vec4::Arg v );
 template<const bool round>
 Col4 FloatToUHalf( Vec4::Arg v )
@@ -4450,7 +4516,7 @@ Col4 FloatToSHalf( Vec4::Arg v )
 	return h;
 }
 
-Vec4 UHalfToFloat( Col4::Arg v )
+inline Vec4 UHalfToFloat( Col4::Arg v )
 {
 	Vec4 f;
 
@@ -4462,7 +4528,7 @@ Vec4 UHalfToFloat( Col4::Arg v )
 	return f;
 }
 
-Vec4 SHalfToFloat( Col4::Arg v )
+inline Vec4 SHalfToFloat( Col4::Arg v )
 {
 	Vec4 f;
 
